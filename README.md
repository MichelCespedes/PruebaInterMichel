# ğŸ¯ Proyecto de PredicciÃ³n de Churn - Sector LogÃ­stica

**Prueba TÃ©cnica: CientÃ­fico de Datos**

SoluciÃ³n end-to-end para predicciÃ³n de churn de clientes utilizando arquitectura Medallion (Bronze â†’ Silver â†’ Gold) con enfoque en gobierno de datos, feature engineering y decisiones de negocio.

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
- [Arquitectura](#arquitectura)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
- [EjecuciÃ³n](#ejecuciÃ³n)
- [Decisiones de Negocio](#decisiones-de-negocio)
- [Resultados](#resultados)
- [PreparaciÃ³n para AWS](#preparaciÃ³n-para-aws)

---

## ğŸ“– DescripciÃ³n del Proyecto

### Objetivo

Desarrollar un modelo predictivo de churn robusto y reproducible que permita identificar clientes en riesgo de abandono, implementando buenas prÃ¡cticas de gobierno de datos y preparÃ¡ndose para productivizaciÃ³n en AWS.

### Contexto de Negocio

El sector logÃ­stica requiere identificar proactivamente clientes en riesgo para:
- **Reducir tasa de abandono** mediante campaÃ±as de retenciÃ³n dirigidas
- **Optimizar recursos** enfocÃ¡ndose en clientes de alto valor en riesgo
- **Mejorar experiencia del cliente** anticipando necesidades

### Dataset

- **Fuente**: `raw_data_customers.csv`
- **Registros**: 110 clientes (con duplicados en datos raw)
- **Features originales**: 10 columnas
- **Variable objetivo**: `churn_label` (0 = No Churn, 1 = Churn)

---

## ğŸ—ï¸ Arquitectura

### Arquitectura Medallion

El proyecto implementa la arquitectura de datos Medallion con tres capas:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CAPA BRONZE                          â”‚
â”‚              (Datos Raw - Sin Transformar)                  â”‚
â”‚                                                             â”‚
â”‚  â€¢ Ingesta tal cual del CSV                                 â”‚
â”‚  â€¢ Preserva estado original                                 â”‚
â”‚  â€¢ Trazabilidad y auditorÃ­a                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CAPA SILVER                          â”‚
â”‚            (Datos Limpios y Governados)                     â”‚
â”‚                                                             â”‚
â”‚  â€¢ Duplicados eliminados                                    â”‚
â”‚  â€¢ Formatos normalizados                                    â”‚
â”‚  â€¢ Outliers corregidos                                      â”‚
â”‚  â€¢ Nulos manejados                                          â”‚
â”‚  â€¢ Datos sensibles hasheados (GDPR)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CAPA GOLD                           â”‚
â”‚            (Datos AnalÃ­ticos - Listos ML)                   â”‚
â”‚                                                             â”‚
â”‚  â€¢ Features RFM (Recency, Frequency, Monetary)              â”‚
â”‚  â€¢ Engagement Score                                         â”‚
â”‚  â€¢ MÃ©tricas de riesgo                                       â”‚
â”‚  â€¢ Variables codificadas                                    â”‚
â”‚  â€¢ Dataset optimizado para modelo                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODELADO MULTI-MODELO                    â”‚
â”‚          (RF, Logistic Regression, XGBoost)                 â”‚
â”‚                                                             â”‚
â”‚  â€¢ Entrenamiento con validaciÃ³n cruzada                     â”‚
â”‚  â€¢ ComparaciÃ³n automÃ¡tica de mÃ©tricas (F1-Score)            â”‚
â”‚  â€¢ SelecciÃ³n automÃ¡tica del mejor modelo                    â”‚
â”‚  â€¢ Persistencia del modelo ganador (PKL)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

1. **Bronze**: Carga datos raw sin transformaciones
2. **Silver**: Aplica gobierno de datos y limpieza
3. **Gold**: Genera features avanzadas para modelado
4. **Modelado**: Entrena y evalÃºa modelo predictivo

---

## ğŸ“ Estructura del Proyecto

```
proyecto_churn/
â”‚
â”œâ”€â”€ datos/
â”‚   â”œâ”€â”€ bronze/                    # ğŸ¥‰ Datos raw
â”‚   â”‚   â””â”€â”€ raw_data_customers.csv
â”‚   â”œâ”€â”€ silver/                    # ğŸ¥ˆ Datos limpios
â”‚   â”‚   â””â”€â”€ clientes_limpios.csv
â”‚   â””â”€â”€ gold/                      # ğŸ¥‡ Datos analÃ­ticos
â”‚       â””â”€â”€ clientes_modelado.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda_exploratorio.ipynb     # ğŸ“Š AnÃ¡lisis exploratorio (Jupyter)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ configuracion.py           # âš™ï¸  ParÃ¡metros centralizados
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ cargar_bronze.py       # ğŸ“¥ Carga a Bronze
â”‚   â”‚
â”‚   â”œâ”€â”€ transformacion/
â”‚   â”‚   â”œâ”€â”€ bronze_a_silver.py     # ğŸ§¹ Limpieza
â”‚   â”‚   â””â”€â”€ silver_a_gold.py       # âš¡ Feature Engineering
â”‚   â”‚
â”‚   â”œâ”€â”€ modelado/
â”‚   â”‚   â””â”€â”€ entrenar_modelo.py     # ğŸ¤– Entrenamiento ML
â”‚   â”‚
â”‚   â””â”€â”€ utilidades/
â”‚       â”œâ”€â”€ hashing.py             # ğŸ” ProtecciÃ³n PII
â”‚       â”œâ”€â”€ limpieza.py            # ğŸ§¼ Funciones limpieza
â”‚       â””â”€â”€ features.py            # ğŸ¯ GeneraciÃ³n features
â”‚
â”œâ”€â”€ modelos/
â”‚   â””â”€â”€ modelo_churn.pkl           # ğŸ’¾ Mejor modelo entrenado (Ganador)
â”‚
â”œâ”€â”€ resultados/
â”‚   â”œâ”€â”€ metricas/
â”‚   â”‚   â””â”€â”€ metricas_todos_modelos.json   # ğŸ“ˆ MÃ©tricas de todos los modelos
â”‚   â””â”€â”€ visualizaciones/
â”‚       â””â”€â”€ evaluacion_[modelo].png      # ğŸ“Š GrÃ¡ficos por modelo
â”‚
â”œâ”€â”€ diagramas/
â”‚   â”œâ”€â”€ arquitectura_local.png     # ğŸ—ï¸  Diagrama local
â”‚   â””â”€â”€ arquitectura_aws.png       # â˜ï¸  Diagrama AWS
â”‚
â”œâ”€â”€ main.py                        # ğŸš€ Script principal
â”œâ”€â”€ requirements.txt               # ğŸ“¦ Dependencias
â””â”€â”€ README.md                      # ğŸ“– Este archivo
```

---

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- Python 3.8+
- pip

### InstalaciÃ³n

1. **Clonar o descargar el proyecto**

```bash
cd proyecto_churn
```

2. **Crear entorno virtual (recomendado)**

```bash
python -m venv venv

# Activar entorno
# Linux/Mac:
source venv/bin/activate

# Windows:
venv\Scripts\activate
```

3. **Instalar dependencias**

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ EjecuciÃ³n

### OpciÃ³n 1: Pipeline Completo (Recomendado)

Ejecuta todo el pipeline de principio a fin:

```bash
python main.py
```

Esto ejecutarÃ¡:
1. âœ… Carga de datos a Bronze
2. âœ… TransformaciÃ³n Bronze â†’ Silver (limpieza)
3. âœ… TransformaciÃ³n Silver â†’ Gold (features)
4. âœ… Entrenamiento del modelo

### OpciÃ³n 2: EjecuciÃ³n por Etapas

Si deseas ejecutar solo ciertas etapas:

```bash
# Solo limpieza de datos
python main.py --solo-limpieza

# Hasta feature engineering
python main.py --solo-features

# Solo entrenamiento (requiere Gold existente)
python main.py --solo-modelo
```

### OpciÃ³n 3: EjecuciÃ³n Manual por Scripts

Ejecutar cada etapa individualmente:

```bash
# 1. Bronze
python src/ingestion/cargar_bronze.py

# 2. Silver
python src/transformacion/bronze_a_silver.py

# 3. Gold
python src/transformacion/silver_a_gold.py

# 4. Modelo
python src/modelado/entrenar_modelo.py
```

### AnÃ¡lisis Exploratorio (EDA)

Para ejecutar el anÃ¡lisis exploratorio:

```bash
# Si tienes Jupyter instalado
jupyter notebook notebooks/eda_exploratorio.ipynb
```

---

## ğŸ’¼ Decisiones de Negocio

### 1. Gobierno de Datos

#### Tratamiento de Duplicados

**Problema Detectado:**
- Registros con mismo `customer_id` pero datos diferentes
- Duplicados completos (todas las columnas iguales)

**DecisiÃ³n:**
- Duplicados completos: Eliminar (informaciÃ³n redundante)
- Duplicados por ID: Mantener registro con `last_purchase_date` mÃ¡s reciente
- **JustificaciÃ³n**: El dato mÃ¡s reciente refleja mejor el estado actual del cliente

#### Hashing de Datos Sensibles (PII)

**Columnas Protegidas:**
- `full_name`
- `email`
- `phone`
- `home_address`

**TÃ©cnica:** SHA-256 con salt

**JustificaciÃ³n de Negocio:**
- Cumplimiento GDPR/CCPA
- Permite anÃ¡lisis sin exponer informaciÃ³n personal
- Mantiene unicidad para joins
- Reproducible con mismo salt

#### Tratamiento de Valores Nulos

| Columna | Estrategia | JustificaciÃ³n de Negocio |
|---------|------------|--------------------------|
| `phone` | CategorÃ­a "MISSING" | Ausencia de telÃ©fono es informaciÃ³n relevante |
| `monthly_spend` | Mediana | Robusta a outliers, representa cliente tÃ­pico |
| `total_shipments` | Mediana | Similar, comportamiento promedio |
| `last_purchase_date` | Forward fill | Conservador, usa Ãºltima fecha conocida |
| `churn_label` | Eliminar registro | Sin etiqueta no se puede entrenar |

#### DetecciÃ³n y CorrecciÃ³n de Outliers

**Umbrales Definidos por Negocio:**

```python
# Gasto mensual
UMBRAL_GASTO_MINIMO = 0      # Negativos son errores
UMBRAL_GASTO_MAXIMO = 15000  # Valores extremos a revisar

# EnvÃ­os
UMBRAL_ENVIOS_MAXIMO = 500   # NÃºmero razonable de envÃ­os
```

**Estrategia:**
- Gastos negativos â†’ Convertir a 0 (error de registro)
- Gastos > 15,000 â†’ Cap al umbral (preservar cliente de alto valor)
- EnvÃ­os extremos â†’ Cap (pueden ser clientes VIP legÃ­timos)

---

### 2. Feature Engineering

#### MÃ©tricas RFM

ImplementaciÃ³n del modelo RFM (Recency, Frequency, Monetary):

**R - Recency (Recencia)**
- **MÃ©trica**: DÃ­as desde Ãºltima compra
- **Negocio**: Indicador mÃ¡s fuerte de churn inminente
- **CategorÃ­as**: Muy Reciente (<30d), Reciente (30-90d), Inactivo (90-180d), Muy Inactivo (>180d)

**F - Frequency (Frecuencia)**
- **MÃ©trica**: Total de envÃ­os histÃ³ricos
- **Negocio**: Indica lealtad y hÃ¡bito de compra
- **Segmentos**: Ocasional (<10), Regular (10-30), Frecuente (30-100), VIP (>100)

**M - Monetary (Monetario)**
- **MÃ©trica**: Gasto mensual promedio
- **Negocio**: Valor econÃ³mico del cliente
- **Segmentos**: Bajo (<$500), Medio ($500-1,500), Alto ($1,500-5,000), Premium (>$5,000)

#### Engagement Score

**FÃ³rmula Ponderada:**

```python
Engagement = (Recencia_Norm Ã— 0.4) + 
             (Frecuencia_Norm Ã— 0.3) + 
             (Gasto_Norm Ã— 0.3)
```

**Pesos Justificados:**
- **Recencia (40%)**: Indicador mÃ¡s fuerte de churn inmediato
- **Frecuencia (30%)**: Indica lealtad y engagement
- **Gasto (30%)**: Representa valor econÃ³mico

**Uso de Negocio:**
- Score bajo (<25): Alta prioridad para retenciÃ³n
- Score alto (>75): Clientes leales, enfoque en upsell

#### Features de Riesgo

Variables creadas especÃ­ficamente para identificar clientes en peligro:

1. **`riesgo_inactividad`**: Recencia > 180 dÃ­as
2. **`riesgo_bajo_engagement`**: Score < 30
3. **`riesgo_nuevo_inactivo`**: Cliente reciente sin actividad
4. **`score_riesgo_churn`**: MÃ©trica combinada de seÃ±ales de riesgo

---

### 3. Modelo de Machine Learning

#### SelecciÃ³n del Modelo: Enfoque Multi-Modelo

El sistema evalÃºa automÃ¡ticamente tres algoritmos para encontrar el mejor balance entre complejidad y capacidad de generalizaciÃ³n:

| Modelo | Rol | Ventajas |
|--------|-----|----------|
| **XGBoost** | SOTA | Alta precisiÃ³n, manejo nativo de nulos y regularizaciÃ³n avanzada. |
| **Random Forest** | Baseline Robusto | Excelente interpretabilidad y manejo automÃ¡tico de features. |
| **Logistic Regression** | Baseline Simple | Alta eficiencia y base probabilÃ­stica sÃ³lida. |

**Criterio de SelecciÃ³n:** El sistema selecciona el modelo con el mejor **CV F1-Score** (validaciÃ³n cruzada). 

**InnovaciÃ³n DinÃ¡mica:** A diferencia de procesos estÃ¡ticos, este pipeline genera una **RazÃ³n TÃ©cnica de SelecciÃ³n** automÃ¡tica que compara el desempeÃ±o del ganador contra los competidores en puntos reales de F1-Score, garantizando transparencia en la decisiÃ³n.

#### ConfiguraciÃ³n de Modelos
Los parÃ¡metros estÃ¡n optimizados para evitar overfitting mediante regularizaciÃ³n y poda. El sistema permite al usuario experimentar con la estabilidad del modelo cambiando el `RANDOM_STATE` en `configuracion.py` para verificar la consistencia de los resultados.

#### MÃ©tricas Priorizadas

Para churn, las mÃ©tricas tienen diferentes implicaciones de negocio:

| MÃ©trica | Importancia | InterpretaciÃ³n de Negocio |
|---------|-------------|---------------------------|
| **Recall** | Alta | Identificar mÃ¡ximo de clientes en riesgo real. FN = Cliente perdido sin intervenciÃ³n |
| **Precision** | Media-Alta | Evitar falsos positivos. FP = Esfuerzo de retenciÃ³n desperdiciado |
| **F1-Score** | Alta | Balance entre Recall y Precision |
| **ROC-AUC** | Media | Capacidad discriminativa general del modelo |

**DecisiÃ³n de Negocio:**
- Priorizar **Recall** sobre Precision.
- **RazÃ³n**: Es mÃ¡s costoso perder un cliente real (Churn) que realizar una campaÃ±a de marketing preventiva sobre un falso positivo.

---

## ğŸ“Š Resultados

### MÃ©tricas del Modelo

Los resultados se generan dinÃ¡micamente en cada ejecuciÃ³n y se consolidan en:
- `resultados/metricas/metricas_todos_modelos.json` (Informe tÃ©cnico exhaustivo con comparativas).
- `resultados/visualizaciones/evaluacion_[modelo].png` (Curvas ROC y Matrices de ConfusiÃ³n).

**Ejemplo de Reporte DinÃ¡mico Sugerido:**
> *"El modelo RandomForest fue seleccionado como ganador debido a que obtuvo el mayor CV F1-Score promedio (0.7989) entre todos los competidores... Comparado con: LogisticRegression (Dif: +0.1533)"*

### Top Features Importantes

El anÃ¡lisis de importancia identifica los factores crÃ­ticos que disparan el churn:

### InterpretaciÃ³n de Negocio

La evaluaciÃ³n final permite segmentar la base de clientes en:
- **True Positives (TP)**: Clientes identificados con Ã©xito en riesgo de abandono. Objetivo de campaÃ±as de retenciÃ³n.
- **False Positives (FP)**: Clientes leales que el modelo marcÃ³ como riesgo. Representan un "seguro de retenciÃ³n" pero con costo operativo.
- **False Negatives (FN)**: El escenario mÃ¡s costoso. Clientes que abandonan sin que el modelo envÃ­e una alerta.

> ğŸ“Š *VisualizaciÃ³n de Matriz de ConfusiÃ³n y Curva ROC disponible en el directorio `resultados/visualizaciones/`.*

---

## â˜ï¸ PreparaciÃ³n para AWS

### Arquitectura Conceptual en AWS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INGESTA DE DATOS                      â”‚
â”‚                                                            â”‚
â”‚  S3 Bucket (Bronze)                                        â”‚
â”‚  â””â”€â”€ raw_data_customers.csv                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   TRANSFORMACIÃ“N (ETL)                     â”‚
â”‚                                                            â”‚
â”‚  AWS Glue Jobs                                             â”‚
â”‚  â”œâ”€â”€ Job 1: Bronze â†’ Silver (Limpieza)                     â”‚
â”‚  â””â”€â”€ Job 2: Silver â†’ Gold (Features)                       â”‚
â”‚                                                            â”‚
â”‚  AWS Glue Data Catalog                                     â”‚
â”‚  â””â”€â”€ churn_db (Base de datos)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ALMACENAMIENTO PROCESADO                  â”‚
â”‚                                                            â”‚
â”‚  S3 Bucket (Silver)                                        â”‚
â”‚  â””â”€â”€ clientes_limpios/                                     â”‚
â”‚                                                            â”‚
â”‚  S3 Bucket (Gold)                                          â”‚
â”‚  â””â”€â”€ clientes_modelado/                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ENTRENAMIENTO ML                          â”‚
â”‚                                                            â”‚
â”‚  Amazon SageMaker                                          â”‚
â”‚  â”œâ”€â”€ Training Job (scikit-learn)                           â”‚
â”‚  â”œâ”€â”€ Model Registry (Gobierno de Versiones y MÃ©tricas)     â”‚
â”‚  â””â”€â”€ Endpoint (Inferencia de Churn en Tiempo Real)         â”‚
â”‚                                                            â”‚
â”‚  S3 Bucket (Modelos)                                       â”‚
â”‚  â””â”€â”€ modelo_churn_vX.tar.gz                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MONITOREO Y ORQUESTACIÃ“N                 â”‚
â”‚                                                            â”‚
â”‚  CloudWatch (Logs y MÃ©tricas Operativas)                   â”‚
â”‚  Step Functions (OrquestaciÃ³n del Pipeline Medallion)      â”‚
â”‚  EventBridge (Scheduling de Ingesta Diaria)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes AWS

#### 1. Amazon S3 (Almacenamiento)

**Buckets por Capa:**
- `s3://churn-data-bronze/` - Datos raw
- `s3://churn-data-silver/` - Datos limpios
- `s3://churn-data-gold/` - Datos analÃ­ticos
- `s3://churn-models/` - Modelos entrenados

**Versionado:** Habilitado en todos los buckets para trazabilidad

#### 2. AWS Glue (ETL)

**Jobs de TransformaciÃ³n:**
- `job_bronze_to_silver.py` - Limpieza y gobierno
- `job_silver_to_gold.py` - Feature engineering

**Data Catalog:**
- Base de datos: `churn_db`
- Tablas: `clientes_bronze`, `clientes_silver`, `clientes_gold`

#### 3. Amazon SageMaker (ML)

**Training:**
- Tipo de instancia: `ml.m5.large`
- Framework: scikit-learn
- Script de entrenamiento: `entrenar_modelo.py`

**Endpoint:**
- Nombre: `churn-predictor`
- Auto-scaling: Basado en invocaciones
- Monitoreo: CloudWatch Model Monitor

#### 4. OrquestaciÃ³n

**AWS Step Functions:**
```json
{
  "Estado Inicial": "Cargar Bronze",
  "Estados": {
    "Cargar Bronze": {
      "Tipo": "Glue Job",
      "Siguiente": "Transformar a Silver"
    },
    "Transformar a Silver": {
      "Tipo": "Glue Job",
      "Siguiente": "Transformar a Gold"
    },
    "Transformar a Gold": {
      "Tipo": "Glue Job",
      "Siguiente": "Entrenar Modelo"
    },
    "Entrenar Modelo": {
      "Tipo": "SageMaker Training",
      "Siguiente": "Evaluar Modelo"
    }
  }
}
```

**Scheduling:**
- EventBridge: EjecuciÃ³n diaria a las 02:00 AM
- Trigger: Nuevos archivos en S3 Bronze

### MigraciÃ³n del CÃ³digo Local a AWS

**Cambios Necesarios:**

1. **ConfiguraciÃ³n de S3:**
```python
import boto3

s3 = boto3.client('s3')

# En lugar de:
df = pd.read_csv('datos/bronze/raw_data_customers.csv')

# Usar:
obj = s3.get_object(Bucket='churn-data-bronze', Key='raw_data_customers.csv')
df = pd.read_csv(obj['Body'])
```

2. **Persistencia de Modelos:**
```python
import joblib
import boto3

# Guardar modelo en S3
with open('/tmp/modelo_churn.pkl', 'wb') as f:
    joblib.dump(modelo, f)

s3.upload_file('/tmp/modelo_churn.pkl', 
               'churn-models', 
               'modelo_churn_v1.pkl')
```

3. **Glue Jobs:**
```python
from awsglue.context import GlueContext
from awsglue.dynamicframe import DynamicFrame

# Leer desde Catalog
df = glueContext.create_dynamic_frame.from_catalog(
    database='churn_db',
    table_name='clientes_bronze'
).toDF()
```

### Costos Estimados (Aproximados)

**Componentes Principales:**

| Servicio | Uso Mensual | Costo Aprox |
|----------|-------------|-------------|
| S3 (3 buckets) | 10 GB | $0.23 |
| Glue (2 jobs/dÃ­a) | 60 DPU-hours | $13.20 |
| SageMaker Training | 1 job/dÃ­a, 0.5h | $37.80 |
| SageMaker Endpoint | 1 instancia 24/7 | $69.12 |
| CloudWatch | Logs estÃ¡ndar | $5.00 |
| **Total Mensual** | | **~$125** |

**Nota**: Costos estimados para regiÃ³n us-east-1, pueden variar

### Seguridad y Cumplimiento

**IAM Roles:**
- `GlueServiceRole` - Para jobs de ETL
- `SageMakerExecutionRole` - Para training/inference
- `LambdaExecutionRole` - Para funciones auxiliares

**EncriptaciÃ³n:**
- S3: SSE-S3 o SSE-KMS
- SageMaker: EncriptaciÃ³n en trÃ¡nsito y reposo
- Glue: EncriptaciÃ³n de datos en ETL

**VPC:**
- Endpoints privados para SageMaker
- Security Groups restrictivos
- No exposiciÃ³n pÃºblica de endpoints

---

## ğŸ“š DocumentaciÃ³n Adicional

### Archivos de ConfiguraciÃ³n

Todos los parÃ¡metros del proyecto estÃ¡n centralizados en:
- `src/configuracion.py`

Para modificar comportamientos, editar este archivo.

### Logs y Trazabilidad

El proyecto genera logs detallados en cada etapa:
- Mensajes informativos con emoji para facilitar lectura
- Registro de decisiones tomadas
- MÃ©tricas de calidad en cada transformaciÃ³n

### Reproducibilidad

**Semillas Aleatorias:**
```python
RANDOM_STATE = 42  # Usado en todos los procesos estocÃ¡sticos
```

**Versionado de Datos:**
- Bronze: Datos con timestamp de ingesta
- Silver/Gold: Metadata de transformaciÃ³n guardada

---

## ğŸ‘¨â€ğŸ’» Autor

**Prueba TÃ©cnica - CientÃ­fico de Datos**

Desarrollado con enfoque en:
- âœ… Gobierno de datos y privacidad
- âœ… Decisiones basadas en negocio
- âœ… CÃ³digo limpio y documentado
- âœ… Arquitectura escalable
- âœ… PreparaciÃ³n para producciÃ³n en AWS

---

## ğŸ“„ Licencia

Este proyecto es parte de una prueba tÃ©cnica para evaluaciÃ³n de capacidades en ciencia de datos y MLOps.

---

## ğŸ”— Referencias

- [AWS Glue Documentation](https://docs.aws.amazon.com/glue/)
- [Amazon SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/)
- [scikit-learn Documentation](https://scikit-learn.org/)
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)