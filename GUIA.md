# üìö GU√çA PASO A PASO - Proyecto de Predicci√≥n de Churn

## Resoluci√≥n Completa de la Prueba T√©cnica

Esta gu√≠a te llevar√° paso a paso por todo el proyecto, desde la configuraci√≥n inicial hasta la presentaci√≥n de resultados.

---

## üéØ FASE 0: Preparaci√≥n del Entorno

### Paso 0.1: Requisitos Previos

Aseg√∫rate de tener instalado:
- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- Git (opcional, para control de versiones)

### Paso 0.2: Crear Entorno Virtual

```bash
# Navegar al directorio del proyecto
cd proyecto_churn

# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# En Linux/Mac:
source venv/bin/activate

# En Windows:
venv\Scripts\activate
```

### Paso 0.3: Instalar Dependencias

```bash
# Instalar todas las librer√≠as necesarias
pip install -r requirements.txt
```

**Librer√≠as principales:**
- pandas: Manipulaci√≥n de datos
- numpy: Operaciones num√©ricas
- scikit-learn: Machine Learning
- matplotlib, seaborn: Visualizaci√≥n

---

## üìä FASE 1: An√°lisis Exploratorio de Datos (EDA)

### Paso 1.1: Ejecutar EDA

```bash
# Opci√≥n A: Como script Python
python notebooks/eda_exploratorio.py

# Opci√≥n B: Si tienes Jupyter (recomendado)
jupyter notebook notebooks/eda_exploratorio.ipynb
```

### Paso 1.2: Analizar Hallazgos del EDA

**Principales problemas identificados:**

1. **Calidad de Datos:**
   - ‚úÖ Duplicados detectados (C001, C003, C012, C023 aparecen repetidos)
   - ‚úÖ Formatos de fecha inconsistentes (DD/MM/YYYY, YYYY-MM-DD, MM/DD/YYYY)
   - ‚úÖ Outliers extremos en monthly_spend (valores negativos, >15000)
   - ‚úÖ Valores nulos en phone, monthly_spend, total_shipments
   - ‚úÖ Datos sensibles sin protecci√≥n (nombres, emails, direcciones)

2. **Distribuci√≥n de Churn:**
   - Revisar si las clases est√°n balanceadas
   - Identificar tasa de churn actual
   - Decisi√≥n: Usar stratify en train/test split

3. **Patrones Identificados:**
   - Recencia es predictor fuerte de churn
   - Clientes inactivos (>180 d√≠as) presentan mayor riesgo
   - Segmentos de bajo gasto tienen mayor tasa de abandono

**Acci√≥n:** Documentar estos hallazgos para justificar decisiones de limpieza

---

## ü•â FASE 2: Capa BRONZE - Datos Raw

### Paso 2.1: Verificar Datos en Bronze

```bash
# Los datos ya deben estar en datos/bronze/raw_data_customers.csv
ls -lh datos/bronze/

# Verificar contenido
head -20 datos/bronze/raw_data_customers.csv
```

### Paso 2.2: Ejecutar Carga a Bronze

```bash
python src/ingestion/cargar_bronze.py
```

**Lo que hace este script:**
- Carga el CSV sin transformaciones
- Registra metadatos (timestamp, # registros, # columnas)
- Realiza an√°lisis inicial de calidad
- Detecta duplicados y nulos
- Preserva datos originales para auditor√≠a

**Salida esperada:**
```
‚ÑπÔ∏è Cargando datos desde: /path/to/bronze/raw_data_customers.csv
‚úÖ Datos cargados exitosamente
   - Registros: 115
   - Columnas: 10
‚ö†Ô∏è  Duplicados completos detectados: X
‚ö†Ô∏è  IDs duplicados detectados: Y
```

---

## ü•à FASE 3: Capa SILVER - Limpieza y Gobierno de Datos

### Paso 3.1: Ejecutar Transformaci√≥n Bronze ‚Üí Silver

```bash
python src/transformacion/bronze_a_silver.py
```

**Transformaciones aplicadas:**

1. **Eliminaci√≥n de Duplicados**
   - Duplicados completos: Se eliminan
   - Duplicados por ID: Se mantiene registro con fecha m√°s reciente
   - **Justificaci√≥n**: Dato m√°s reciente refleja mejor el estado actual

2. **Normalizaci√≥n de Fechas**
   - M√∫ltiples formatos ‚Üí YYYY-MM-DD est√°ndar
   - Uso de pandas.to_datetime con inferencia autom√°tica
   - **Justificaci√≥n**: Consistencia para c√°lculos temporales

3. **Correcci√≥n de Outliers**
   - Gastos negativos ‚Üí 0 (error de registro)
   - Gastos >$15,000 ‚Üí Cap al umbral
   - Env√≠os >500 ‚Üí Cap al umbral
   - **Justificaci√≥n**: Umbrales basados en conocimiento del negocio

4. **Tratamiento de Nulos**
   - phone ‚Üí "MISSING" (categor√≠a especial)
   - monthly_spend ‚Üí Mediana (robusta a outliers)
   - total_shipments ‚Üí Mediana
   - churn_label ‚Üí Eliminar registro (sin etiqueta no entrenable)
   - **Justificaci√≥n**: Estrategias diferenciadas seg√∫n impacto

5. **Hashing de Datos Sensibles (PII)**
   - full_name, email, phone, home_address ‚Üí SHA-256
   - **Justificaci√≥n**: Cumplimiento GDPR/privacidad

**Salida esperada:**
```
[1/8] Cargando datos de capa Bronze...
‚úÖ Datos cargados: 115 registros

[2/8] Detectando y eliminando duplicados...
‚úÖ Eliminados X duplicados

[3/8] Normalizando formatos de fecha...
‚úÖ Fechas normalizadas

[4/8] Convirtiendo tipos de datos...
‚úÖ Tipos de datos convertidos

[5/8] Detectando y corrigiendo outliers...
‚úÖ Outliers corregidos

[6/8] Tratando valores nulos...
‚úÖ Valores nulos manejados

[7/8] Hasheando datos sensibles (PII)...
‚úÖ Datos sensibles protegidos

[8/8] Validando calidad de datos Silver...
‚úÖ Datos Silver guardados en: datos/silver/clientes_limpios.csv
```

### Paso 3.2: Verificar Datos Silver

```bash
# Ver primeras l√≠neas
head -5 datos/silver/clientes_limpios.csv

# Contar registros
wc -l datos/silver/clientes_limpios.csv
```

---

## ü•á FASE 4: Capa GOLD - Feature Engineering

### Paso 4.1: Ejecutar Transformaci√≥n Silver ‚Üí Gold

```bash
python src/transformacion/silver_a_gold.py
```

**Features Generadas:**

1. **M√©tricas RFM (Recency, Frequency, Monetary)**
   - `recencia_dias`: D√≠as desde √∫ltima compra
   - `categoria_recencia`: Muy Reciente | Reciente | Inactivo | Muy Inactivo
   - `antiguedad_dias`: Tiempo como cliente
   - `segmento_gasto`: Bajo | Medio | Alto | Premium
   - `segmento_frecuencia`: Ocasional | Regular | Frecuente | VIP

2. **Engagement Score**
   - `engagement_score`: Score 0-100 ponderado
   - F√≥rmula: (Recencia √ó 0.4) + (Frecuencia √ó 0.3) + (Gasto √ó 0.3)
   - `nivel_engagement`: Bajo | Medio | Alto | Muy Alto

3. **Features de Comportamiento**
   - `gasto_por_envio`: Ticket promedio
   - `dias_entre_compras`: Frecuencia temporal
   - `cliente_activo_reciente`: Flag binario
   - `cliente_alto_valor`: Flag binario

4. **Features de Riesgo**
   - `riesgo_inactividad`: Flag (recencia >180 d√≠as)
   - `riesgo_bajo_engagement`: Flag (score <30)
   - `score_riesgo_churn`: M√©trica combinada
   - `nivel_riesgo`: Bajo | Medio | Alto | Cr√≠tico

5. **Encoding**
   - Variables categ√≥ricas ‚Üí One-Hot Encoding
   - Dataset optimizado para ML

**Salida esperada:**
```
[1/4] Cargando datos de capa Silver...
‚úÖ Datos Silver cargados: ~100 registros

[2/4] Generando features de modelado...
‚ÑπÔ∏è Calculando recencia de clientes
‚ÑπÔ∏è Calculando antig√ºedad de clientes
‚ÑπÔ∏è Categorizando nivel de gasto
‚úÖ Features generadas: 30+ nuevas columnas

[3/4] Preparando dataset para modelado...
‚úÖ Dataset preparado: 50+ features finales

[4/4] Validando dataset Gold...
Distribuci√≥n de churn_label:
  - No Churn (0): X (XX.X%)
  - Churn (1): Y (YY.Y%)
‚úÖ Dataset Gold guardado en: datos/gold/clientes_modelado.csv
```

### Paso 4.2: Verificar Datos Gold

```bash
# Ver estructura
head -3 datos/gold/clientes_modelado.csv

# Contar features
head -1 datos/gold/clientes_modelado.csv | awk -F',' '{print NF}'
```

---

## ü§ñ FASE 5: Modelado - Entrenamiento

### Paso 5.1: Entrenar Modelo de Churn

```bash
python src/modelado/entrenar_modelo.py
```

**Proceso de Entrenamiento:**

1. **Carga de Datos Gold**
   - Lee dataset optimizado
   - Verifica presencia de todas las columnas

2. **Preparaci√≥n de Datos**
   - Separaci√≥n X (features) y y (target)
   - Train/Test Split (75%/25%)
   - Estratificaci√≥n por churn_label

3. **Entrenamiento del Modelo**
   - Algoritmo: Random Forest Classifier
   - Par√°metros:
     * n_estimators: 100
     * max_depth: 10
     * class_weight: 'balanced' (manejo de desbalance)
     * random_state: 42 (reproducibilidad)

4. **Evaluaci√≥n**
   - M√©tricas en conjunto de prueba
   - Validaci√≥n cruzada 5-fold
   - Importancia de features
   - Matriz de confusi√≥n

5. **Persistencia**
   - Modelo guardado en: `modelos/modelo_churn.pkl`
   - M√©tricas guardadas en: `resultados/metricas/metricas_modelo.json`
   - Visualizaciones en: `resultados/visualizaciones/evaluacion_modelo.png`

**Salida esperada:**
```
ENTRENANDO MODELO RANDOM FOREST

Par√°metros del modelo:
  - n_estimators: 100
  - max_depth: 10
  - class_weight: balanced
  
‚úÖ Modelo entrenado exitosamente

M√âTRICAS EN CONJUNTO DE PRUEBA:
‚úÖ Accuracy: 0.XXXX
‚úÖ Precision (Churn): 0.XXXX
‚úÖ Recall (Churn): 0.XXXX
‚úÖ F1-Score (Churn): 0.XXXX
‚úÖ ROC-AUC: 0.XXXX

TOP 10 FEATURES M√ÅS IMPORTANTES:
recencia_dias: 0.XXXX
engagement_score: 0.XXXX
monthly_spend: 0.XXXX
...

‚úÖ ENTRENAMIENTO COMPLETADO EXITOSAMENTE
```

### Paso 5.2: Revisar Resultados

```bash
# Ver m√©tricas completas
cat resultados/metricas/metricas_modelo.json

# Ver visualizaciones (abrirlas en visor de im√°genes)
open resultados/visualizaciones/evaluacion_modelo.png  # Mac
xdg-open resultados/visualizaciones/evaluacion_modelo.png  # Linux
# Windows: doble clic en el archivo
```

---

## üöÄ FASE 6: Ejecuci√≥n del Pipeline Completo

### Opci√≥n A: Pipeline Completo Automatizado

```bash
# Ejecutar TODO de principio a fin
python main.py
```

Este comando ejecuta:
1. ‚úÖ Bronze: Carga de datos
2. ‚úÖ Silver: Limpieza y gobierno
3. ‚úÖ Gold: Feature engineering
4. ‚úÖ Modelado: Entrenamiento y evaluaci√≥n

**Duraci√≥n aproximada:** 2-5 minutos

### Opci√≥n B: Ejecuci√≥n por Etapas

```bash
# Solo limpieza (Bronze ‚Üí Silver)
python main.py --solo-limpieza

# Hasta features (Bronze ‚Üí Silver ‚Üí Gold)
python main.py --solo-features

# Solo entrenamiento (requiere Gold existente)
python main.py --solo-modelo
```

---

## üìã FASE 7: Interpretaci√≥n de Resultados de Negocio

### Paso 7.1: Analizar M√©tricas del Modelo

**M√©tricas Clave:**

1. **Accuracy (Exactitud)**
   - Qu√© mide: % de predicciones correctas totales
   - Interpretaci√≥n: Confiabilidad general del modelo
   - Meta: >0.80

2. **Precision (Churn)**
   - Qu√© mide: De los que predecimos como churn, cu√°ntos realmente har√°n churn
   - Interpretaci√≥n de negocio: Eficiencia de campa√±as de retenci√≥n
   - Ejemplo: Precision=0.75 ‚Üí De cada 100 clientes que marcamos como riesgo, 75 realmente se ir√°n
   - Meta: >0.70

3. **Recall (Churn)**
   - Qu√© mide: De los que realmente har√°n churn, cu√°ntos identificamos
   - Interpretaci√≥n de negocio: Cobertura de clientes en riesgo
   - Ejemplo: Recall=0.82 ‚Üí Identificamos 82 de cada 100 clientes que se ir√°n
   - Meta: >0.75 (prioridad en churn)

4. **F1-Score**
   - Qu√© mide: Balance entre Precision y Recall
   - Interpretaci√≥n: M√©trica equilibrada de performance
   - Meta: >0.75

5. **ROC-AUC**
   - Qu√© mide: Capacidad discriminativa del modelo
   - Interpretaci√≥n: Qu√© tan bien separa clases
   - Meta: >0.80

### Paso 7.2: Interpretar Matriz de Confusi√≥n

```
                 Predicho
              No Churn  Churn
Real  
No Churn       TN        FP
Churn          FN        TP
```

**Significado de Negocio:**
- **TN (True Negative)**: Clientes leales correctamente identificados ‚Üí No necesitan intervenci√≥n
- **FP (False Positive)**: Falsos riesgos ‚Üí Esfuerzo de retenci√≥n desperdiciado
- **FN (False Negative)**: Churn no detectado ‚Üí P√©rdida de cliente sin intervenci√≥n
- **TP (True Positive)**: Churn correctamente identificado ‚Üí Oportunidad de retenci√≥n

**Costo de Errores:**
- FP: Costo de campa√±a de retenci√≥n innecesaria (~$50 por cliente)
- FN: P√©rdida de lifetime value del cliente (~$1,000-$5,000)
- **Conclusi√≥n**: Preferimos FP sobre FN (mejor prevenir de m√°s que de menos)

### Paso 7.3: Analizar Features Importantes

Las top features indican qu√© variables son m√°s predictivas de churn:

**T√≠picamente encontrar√°s:**
1. `recencia_dias` - D√≠as sin comprar (M√ÅS IMPORTANTE)
2. `engagement_score` - Nivel de engagement
3. `monthly_spend` - Valor del cliente
4. `total_shipments` - Frecuencia hist√≥rica
5. `antiguedad_dias` - Tiempo como cliente

**Decisiones de Negocio Basadas en Features:**
- Si recencia_dias es #1 ‚Üí Enfocarse en campa√±as de reactivaci√≥n
- Si engagement_score es importante ‚Üí Mejorar experiencia del cliente
- Si monthly_spend alto ‚Üí Programas VIP de retenci√≥n

---

## üìä FASE 8: Documentaci√≥n de Decisiones

### Paso 8.1: Documentar en README

El README.md ya contiene toda la documentaci√≥n necesaria. Aseg√∫rate de:

1. ‚úÖ Explicar arquitectura Medallion
2. ‚úÖ Justificar cada decisi√≥n de limpieza
3. ‚úÖ Justificar features creadas
4. ‚úÖ Explicar selecci√≥n del modelo
5. ‚úÖ Incluir interpretaci√≥n de negocio

### Paso 8.2: Preparar Material de Presentaci√≥n

Para la presentaci√≥n de 20 minutos, prepara:

**Estructura Sugerida:**

1. **Contexto (2 min)**
   - Problema de negocio
   - Dataset y desaf√≠os

2. **Arquitectura (3 min)**
   - Medallion: Bronze ‚Üí Silver ‚Üí Gold
   - Diagrama visual

3. **Gobierno de Datos (5 min)**
   - Problemas identificados en EDA
   - Decisiones de limpieza con justificaci√≥n
   - Hashing de PII para privacidad

4. **Feature Engineering (4 min)**
   - RFM y por qu√© es relevante
   - Engagement Score
   - Features de riesgo

5. **Modelo y Resultados (4 min)**
   - Random Forest: por qu√©
   - M√©tricas clave
   - Interpretaci√≥n de negocio

6. **AWS y Escalabilidad (2 min)**
   - Arquitectura propuesta
   - Servicios clave (S3, Glue, SageMaker)

**Materiales:**
- Diagramas en `diagramas/arquitectura_*.txt`
- Visualizaciones en `resultados/visualizaciones/`
- M√©tricas en `resultados/metricas/metricas_modelo.json`

---

## ‚òÅÔ∏è FASE 9: Preparaci√≥n para AWS (Conceptual)

### Paso 9.1: Revisar Arquitectura AWS

```bash
# Ver diagrama completo de AWS
cat diagramas/arquitectura_aws.txt
```

**Componentes Clave a Mencionar:**

1. **Almacenamiento:** S3 con estructura Medallion
   - Bronze, Silver, Gold en buckets separados
   - Versionado habilitado
   - Encriptaci√≥n SSE-S3

2. **ETL:** AWS Glue
   - Glue Jobs para transformaciones
   - Glue Data Catalog para metadata
   - Crawlers para descubrimiento de schema

3. **ML:** Amazon SageMaker
   - Training Jobs con scikit-learn
   - Model Registry para versionado
   - Endpoints para inferencia

4. **Orquestaci√≥n:** Step Functions + EventBridge
   - Pipeline automatizado
   - Manejo de errores
   - Scheduling

5. **Monitoreo:** CloudWatch
   - Logs centralizados
   - M√©tricas de performance
   - Alarmas

### Paso 9.2: Migraci√≥n Conceptual

**Cambios Necesarios en C√≥digo:**

```python
# Local
df = pd.read_csv('datos/bronze/raw_data_customers.csv')

# AWS
import boto3
s3 = boto3.client('s3')
obj = s3.get_object(Bucket='churn-data-bronze', 
                    Key='raw_data_customers.csv')
df = pd.read_csv(obj['Body'])
```

**No es necesario implementar**, solo explicar la estrategia.

---

## ‚úÖ CHECKLIST FINAL

Antes de la presentaci√≥n, verificar:

### Entregables T√©cnicos:
- [ ] C√≥digo organizado en carpetas (src/, datos/, notebooks/)
- [ ] Todos los scripts ejecutan sin errores
- [ ] README.md completo con documentaci√≥n
- [ ] Diagramas de arquitectura (local + AWS)
- [ ] Resultados generados (modelo, m√©tricas, visualizaciones)
- [ ] requirements.txt con dependencias

### Documentaci√≥n de Decisiones:
- [ ] Cada transformaci√≥n tiene justificaci√≥n de negocio
- [ ] Estrategias de nulos documentadas
- [ ] Detecci√≥n de outliers justificada
- [ ] Feature engineering explicado
- [ ] Selecci√≥n de modelo justificada
- [ ] M√©tricas priorizadas explicadas

### Preparaci√≥n AWS:
- [ ] Diagrama de arquitectura AWS revisado
- [ ] Servicios clave identificados (S3, Glue, SageMaker)
- [ ] Estrategia de migraci√≥n clara
- [ ] Costos estimados (opcional pero impresionante)

---

## üé§ CONSEJOS PARA LA PRESENTACI√ìN

1. **Enf√≥cate en Negocio, No en Matem√°ticas**
   - Menos: "Usamos la mediana porque es robusta a outliers seg√∫n la distribuci√≥n de Cauchy..."
   - M√°s: "Usamos la mediana porque representa mejor a un cliente t√≠pico sin distorsi√≥n por valores extremos"

2. **Muestra el Impacto**
   - "Con Recall de 82%, identificamos 82 de cada 100 clientes en riesgo, permitiendo intervenci√≥n proactiva"
   - "Esto puede prevenir p√©rdidas de hasta $82,000 mensuales (asumiendo $1,000 LTV por cliente)"

3. **Demuestra Pensamiento Cr√≠tico**
   - "Priorizamos Recall sobre Precision porque el costo de perder un cliente ($1,000+) supera el costo de una campa√±a de retenci√≥n ($50)"

4. **Arquitectura AWS = Escalabilidad**
   - "Este proyecto est√° dise√±ado para escalar de 110 clientes a millones usando S3 + Glue + SageMaker"
   - "El pipeline es automatizable con Step Functions para re-entrenamiento diario"

5. **Gobierno de Datos = Profesionalismo**
   - "Implementamos hashing SHA-256 de PII para cumplimiento GDPR"
   - "Arquitectura Medallion garantiza trazabilidad y auditabilidad"

---

## üö® TROUBLESHOOTING

### Error: "FileNotFoundError: No se encuentra el archivo"
**Soluci√≥n:** Verifica que est√©s en el directorio ra√≠z del proyecto
```bash
pwd  # Debe mostrar /path/to/proyecto_churn
```

### Error: "ModuleNotFoundError: No module named 'pandas'"
**Soluci√≥n:** Instalar dependencias
```bash
pip install -r requirements.txt
```

### Error: "ValueError: Falta la variable objetivo 'churn_label'"
**Soluci√≥n:** Ejecutar primero las capas anteriores
```bash
python src/transformacion/bronze_a_silver.py
python src/transformacion/silver_a_gold.py
```

### Advertencia: "class_weight='balanced' but classes are balanced"
**Soluci√≥n:** No es un error, es informativo. El modelo ajusta pesos autom√°ticamente.

---

## üìö RECURSOS ADICIONALES

- **Medallion Architecture:** [Databricks Glossary](https://www.databricks.com/glossary/medallion-architecture)
- **AWS Glue:** [Developer Guide](https://docs.aws.amazon.com/glue/)
- **SageMaker:** [Getting Started](https://docs.aws.amazon.com/sagemaker/)
- **Random Forest:** [scikit-learn Docs](https://scikit-learn.org/stable/modules/ensemble.html#forest)

---

## üéØ RESUMEN EJECUTIVO

Este proyecto demuestra:

1. ‚úÖ **Gobierno de Datos**: Manejo profesional de datos sucios con decisiones justificadas
2. ‚úÖ **Feature Engineering**: Creaci√≥n de variables predictivas basadas en negocio (RFM)
3. ‚úÖ **Modelado Robusto**: Random Forest con validaci√≥n cruzada y m√©tricas interpretables
4. ‚úÖ **Arquitectura Escalable**: Dise√±o Medallion preparado para producci√≥n en AWS
5. ‚úÖ **Documentaci√≥n Clara**: C√≥digo comentado y decisiones explicadas

**Mensaje Clave:** No solo resolviste un problema t√©cnico de ML, demostraste capacidad de traducir requerimientos de negocio en soluciones escalables con gobierno de datos s√≥lido.

¬°√âxito en la presentaci√≥n! üöÄ